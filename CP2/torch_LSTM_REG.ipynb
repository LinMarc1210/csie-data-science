{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load torch_LSTM_REG.py\n",
    "#%% ============================import============================\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#%% ============================load data============================\n",
    "# 設定 LSTM 往前看的筆數和預測筆數\n",
    "LookBackNum = 12\n",
    "ForecastNum = 48\n",
    "\n",
    "# 載入訓練資料\n",
    "DataName = os.getcwd() + '/ExampleTrainData(AVG)/AvgDATA_17.csv'\n",
    "SourceData = pd.read_csv(DataName, encoding='utf-8')\n",
    "\n",
    "# 迴歸分析用資料\n",
    "Regression_X_train = SourceData[['WindSpeed(m/s)', 'Pressure(hpa)', 'Temperature(°C)', 'Humidity(%)', 'Sunlight(Lux)']].values\n",
    "Regression_y_train = SourceData[['Power(mW)']].values\n",
    "\n",
    "# LSTM 用資料\n",
    "AllOutPut = SourceData[['WindSpeed(m/s)', 'Pressure(hpa)', 'Temperature(°C)', 'Humidity(%)', 'Sunlight(Lux)']].values\n",
    "\n",
    "# 正規化\n",
    "LSTM_MinMaxModel = MinMaxScaler().fit(AllOutPut)\n",
    "AllOutPut_MinMax = LSTM_MinMaxModel.transform(AllOutPut)\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "for i in range(LookBackNum, len(AllOutPut_MinMax)):\n",
    "    X_train.append(AllOutPut_MinMax[i - LookBackNum:i, :])\n",
    "    y_train.append(AllOutPut_MinMax[i, :])\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% ============================定義 PyTorch Dataset============================\n",
    "class WeatherDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "\n",
    "train_dataset = WeatherDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% ============================建置 LSTM 模型============================\n",
    "class WeatherLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size):\n",
    "        super(WeatherLSTM, self).__init__()\n",
    "        self.lstm1 = nn.LSTM(input_size, hidden_sizes[0], batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(hidden_sizes[0], hidden_sizes[1], batch_first=True)\n",
    "        self.lstm3 = nn.LSTM(hidden_sizes[1], hidden_sizes[2], batch_first=True)\n",
    "        self.lstm4 = nn.LSTM(hidden_sizes[2], hidden_sizes[3], batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_sizes[3], output_size)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm1(x)\n",
    "        x, _ = self.lstm2(x)\n",
    "        x, _ = self.lstm3(x)\n",
    "        x, _ = self.lstm4(x)\n",
    "        x = self.dropout(x[:, -1, :])  # 取最後一個時間步的輸出\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "#%%============================device============================\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 0.4286292816807584\n",
      "Epoch 2/100, Loss: 0.162674078127233\n",
      "Epoch 3/100, Loss: 0.10684981233463055\n",
      "Epoch 4/100, Loss: 0.082090329833147\n",
      "Epoch 5/100, Loss: 0.06430500927494794\n",
      "Epoch 6/100, Loss: 0.05582416857161173\n",
      "Epoch 7/100, Loss: 0.051033507305674436\n",
      "Epoch 8/100, Loss: 0.046360711771540525\n",
      "Epoch 9/100, Loss: 0.04283840945217668\n",
      "Epoch 10/100, Loss: 0.04081233499980554\n",
      "Epoch 11/100, Loss: 0.0381209036199058\n",
      "Epoch 12/100, Loss: 0.035912410424249926\n",
      "Epoch 13/100, Loss: 0.03503639741641719\n",
      "Epoch 14/100, Loss: 0.03352504409849644\n",
      "Epoch 15/100, Loss: 0.03246055448018923\n",
      "Epoch 16/100, Loss: 0.031601531203927065\n",
      "Epoch 17/100, Loss: 0.030494513580711875\n",
      "Epoch 18/100, Loss: 0.02959448053705983\n",
      "Epoch 19/100, Loss: 0.029084371630011534\n",
      "Epoch 20/100, Loss: 0.02832952664211029\n",
      "Epoch 21/100, Loss: 0.02784516639644053\n",
      "Epoch 22/100, Loss: 0.027377169306685285\n",
      "Epoch 23/100, Loss: 0.02668928305005155\n",
      "Epoch 24/100, Loss: 0.026189915381553696\n",
      "Epoch 25/100, Loss: 0.025809808338924153\n",
      "Epoch 26/100, Loss: 0.02515570274213465\n",
      "Epoch 27/100, Loss: 0.024862992872552173\n",
      "Epoch 28/100, Loss: 0.024370306512204613\n",
      "Epoch 29/100, Loss: 0.023999933880276797\n",
      "Epoch 30/100, Loss: 0.023366839602226165\n",
      "Epoch 31/100, Loss: 0.022753430575859254\n",
      "Epoch 32/100, Loss: 0.02128344129134969\n",
      "Epoch 33/100, Loss: 0.020020588051255155\n",
      "Epoch 34/100, Loss: 0.018627771335404095\n",
      "Epoch 35/100, Loss: 0.018144225338246764\n",
      "Epoch 36/100, Loss: 0.017275961638405557\n",
      "Epoch 37/100, Loss: 0.01691461958718009\n",
      "Epoch 38/100, Loss: 0.016457153893098597\n",
      "Epoch 39/100, Loss: 0.016190657982739005\n",
      "Epoch 40/100, Loss: 0.015804003447112514\n",
      "Epoch 41/100, Loss: 0.015643088056183443\n",
      "Epoch 42/100, Loss: 0.015350855568923601\n",
      "Epoch 43/100, Loss: 0.01509120515206965\n",
      "Epoch 44/100, Loss: 0.014781184653501684\n",
      "Epoch 45/100, Loss: 0.01447163767567495\n",
      "Epoch 46/100, Loss: 0.01430184441823058\n",
      "Epoch 47/100, Loss: 0.014412001411362393\n",
      "Epoch 48/100, Loss: 0.01393708227792891\n",
      "Epoch 49/100, Loss: 0.013695212421802485\n",
      "Epoch 50/100, Loss: 0.013700374084093222\n",
      "Epoch 51/100, Loss: 0.013425379355506199\n",
      "Epoch 52/100, Loss: 0.013328064051343173\n",
      "Epoch 53/100, Loss: 0.013403158248742907\n",
      "Epoch 54/100, Loss: 0.013249891015087686\n",
      "Epoch 55/100, Loss: 0.013231135745782678\n",
      "Epoch 56/100, Loss: 0.013056027566696085\n",
      "Epoch 57/100, Loss: 0.013108480108402125\n",
      "Epoch 58/100, Loss: 0.012948667039958442\n",
      "Epoch 59/100, Loss: 0.012731409109220273\n",
      "Epoch 60/100, Loss: 0.012726719150455987\n",
      "Epoch 61/100, Loss: 0.012772460831556379\n",
      "Epoch 62/100, Loss: 0.012779006098465221\n",
      "Epoch 63/100, Loss: 0.012688649182276027\n",
      "Epoch 64/100, Loss: 0.012711888065607083\n",
      "Epoch 65/100, Loss: 0.01240802592620617\n",
      "Epoch 66/100, Loss: 0.012403018681741342\n",
      "Epoch 67/100, Loss: 0.012566770608650475\n",
      "Epoch 68/100, Loss: 0.012397417185328356\n",
      "Epoch 69/100, Loss: 0.012546078551833222\n",
      "Epoch 70/100, Loss: 0.012427166036171158\n",
      "Epoch 71/100, Loss: 0.012370909586912247\n",
      "Epoch 72/100, Loss: 0.012251962112580858\n",
      "Epoch 73/100, Loss: 0.012178117977228106\n",
      "Epoch 74/100, Loss: 0.012289899605803373\n",
      "Epoch 75/100, Loss: 0.012296649354805306\n",
      "Epoch 76/100, Loss: 0.012291690788981392\n",
      "Epoch 77/100, Loss: 0.012038433129285894\n",
      "Epoch 78/100, Loss: 0.012040667463003136\n",
      "Epoch 79/100, Loss: 0.012096792414057546\n",
      "Epoch 80/100, Loss: 0.011949871780305373\n",
      "Epoch 81/100, Loss: 0.012144740670919418\n",
      "Epoch 82/100, Loss: 0.0120888711294023\n",
      "Epoch 83/100, Loss: 0.012073391844041464\n",
      "Epoch 84/100, Loss: 0.011899624860323057\n",
      "Epoch 85/100, Loss: 0.012064449420971115\n",
      "Epoch 86/100, Loss: 0.012087873433057854\n",
      "Epoch 87/100, Loss: 0.012057148533441671\n",
      "Epoch 88/100, Loss: 0.011950005572743533\n",
      "Epoch 89/100, Loss: 0.01197273256938632\n",
      "Epoch 90/100, Loss: 0.011842549369647735\n",
      "Epoch 91/100, Loss: 0.011841957639085084\n",
      "Epoch 92/100, Loss: 0.011822040033776586\n",
      "Epoch 93/100, Loss: 0.011711060932678421\n",
      "Epoch 94/100, Loss: 0.011698097808331979\n",
      "Epoch 95/100, Loss: 0.011643759429273082\n",
      "Epoch 96/100, Loss: 0.011788500836346208\n",
      "Epoch 97/100, Loss: 0.011840847411715403\n",
      "Epoch 98/100, Loss: 0.011754383151305885\n",
      "Epoch 99/100, Loss: 0.011840921213350645\n",
      "Epoch 100/100, Loss: 0.011758953582768033\n",
      "LSTM Model Saved\n"
     ]
    }
   ],
   "source": [
    "#%%============================initial model============================\n",
    "# 模型初始化\n",
    "input_size = 5\n",
    "hidden_sizes = [512, 256, 128, 32]\n",
    "output_size = 5\n",
    "model = WeatherLSTM(input_size, hidden_sizes, output_size).to(device)\n",
    "\n",
    "lambda_l1 = 1e-5  # L1 正则化系数\n",
    "lambda_l2 = 1e-4  # L2 正则化系数\n",
    "#============================訓練模型============================\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=lambda_l2)  # L2 正则化\n",
    "\n",
    "# 訓練\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "          # 移動資料到 GPU\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "\n",
    "        l1_regularization = sum(torch.sum(torch.abs(param)) for param in model.parameters())\n",
    "        loss += lambda_l1 * l1_regularization\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Loss: {epoch_loss / len(train_loader)}\")\n",
    "\n",
    "# 保存模型\n",
    "torch.save(model.state_dict(), f'WeatherLSTM_{pd.Timestamp.now().strftime(\"%Y-%m-%dT%H_%M_%SZ\")}.pth')\n",
    "print(\"LSTM Model Saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression Model Saved\n",
      "Intercept: [-221.39953665]\n",
      "Coefficients: [[   0.          135.11381615  117.68809059   23.89564382 1761.56873922]]\n",
      "R-squared: 0.899519098844525\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#%% ============================回歸模型============================\n",
    "RegressionModel = LinearRegression()\n",
    "RegressionModel.fit(LSTM_MinMaxModel.transform(Regression_X_train), Regression_y_train)\n",
    "\n",
    "# 保存回歸模型\n",
    "joblib.dump(RegressionModel, f'WeatherRegression_{pd.Timestamp.now().strftime(\"%Y-%m-%dT%H_%M_%SZ\")}')\n",
    "print(\"Regression Model Saved\")\n",
    "print(\"Intercept:\", RegressionModel.intercept_)\n",
    "print(\"Coefficients:\", RegressionModel.coef_)\n",
    "print(\"R-squared:\", RegressionModel.score(LSTM_MinMaxModel.transform(Regression_X_train), Regression_y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'WeatherLSTM_2024-11-27T16_00_12Z.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# 載入 LSTM 模型\u001b[39;00m\n\u001b[0;32m      9\u001b[0m model \u001b[38;5;241m=\u001b[39m WeatherLSTM(input_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, hidden_sizes\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m512\u001b[39m, \u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m32\u001b[39m], output_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mWeatherLSTM_2024-11-27T16_00_12Z.pth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mweights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m)\n\u001b[0;32m     11\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     12\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[1;32md:\\Course\\DataScience\\testenv\\Lib\\site-packages\\torch\\serialization.py:1319\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m   1317\u001b[0m     pickle_load_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1319\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m   1321\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m   1322\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m   1323\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m   1324\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[1;32md:\\Course\\DataScience\\testenv\\Lib\\site-packages\\torch\\serialization.py:659\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    657\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    658\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 659\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    660\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    661\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[1;32md:\\Course\\DataScience\\testenv\\Lib\\site-packages\\torch\\serialization.py:640\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    639\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[1;32m--> 640\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'WeatherLSTM_2024-11-27T16_00_12Z.pth'"
     ]
    }
   ],
   "source": [
    "\n",
    "#%% ============================預測============================\n",
    "# 載入模型\n",
    "import torch\n",
    "\n",
    "# 設定裝置\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "##記得要改模型名稱\n",
    "# 載入 LSTM 模型\n",
    "model = WeatherLSTM(input_size=5, hidden_sizes=[512, 256, 128, 32], output_size=5)\n",
    "model.load_state_dict(torch.load('WeatherLSTM_2024-11-27T16_00_12Z.pth',weights_only=True))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# 載入迴歸模型\n",
    "RegressionModel = joblib.load('WeatherRegression_2024-11-27T16_09_45Z')\n",
    "\n",
    "# 載入測試資料\n",
    "DataName = os.getcwd() + r\"/ExampleTestData/upload.csv\"\n",
    "SourceData = pd.read_csv(DataName, encoding='utf-8')\n",
    "target = ['序號']\n",
    "EXquestion = SourceData[target].values\n",
    "\n",
    "PredictOutput = []  # 存放預測值 (天氣參數)\n",
    "PredictPower = []   # 存放預測值 (發電量)\n",
    "\n",
    "count = 0\n",
    "while count < len(EXquestion):\n",
    "    print(\"count :\", count)\n",
    "    LocationCode = int(EXquestion[count].item())\n",
    "    strLocationCode = str(LocationCode)[-2:]\n",
    "    if LocationCode < 10:\n",
    "        strLocationCode = \"0\" + str(LocationCode)\n",
    "\n",
    "    DataName = os.getcwd() + f\"/ExampleTrainData(IncompleteAVG)/IncompleteAvgDATA_{strLocationCode}.csv\"\n",
    "    SourceData = pd.read_csv(DataName, encoding=\"utf-8\")\n",
    "    ReferTitle = SourceData[['Serial']].values\n",
    "    ReferData = SourceData[['WindSpeed(m/s)', 'Pressure(hpa)', 'Temperature(°C)', 'Humidity(%)', 'Sunlight(Lux)']].values\n",
    "\n",
    "    inputs = []  # 存放參考資料\n",
    "    # 找到相同的一天，把 12 個資料都加進 inputs\n",
    "    for DaysCount in range(len(ReferTitle)):\n",
    "        if str(int(ReferTitle[DaysCount].item()))[:8] == str(int(EXquestion[count].item()))[:8]:\n",
    "            TempData = ReferData[DaysCount].reshape(1, -1)  # Shape: (1, 5)\n",
    "            TempData = LSTM_MinMaxModel.transform(TempData)\n",
    "            TempData = TempData.squeeze(0)  # 去掉第一维，形状变为 (5,)\n",
    "            inputs.append(TempData)\n",
    "\n",
    "            # print(\"TempData shape:\", TempData.shape)  # 應為 (1, 5)\n",
    "\n",
    "    inputs = torch.tensor(inputs, dtype=torch.float32).to(device)  # 將 inputs 轉成 PyTorch Tensor\n",
    "    # 預測\n",
    "    with torch.no_grad():  # 禁止梯度计算\n",
    "        for i in range(ForecastNum):\n",
    "            # 将新的预测值加入参考数据 (用自己的预测值往前看)\n",
    "            if i > 0:\n",
    "                new_prediction = torch.tensor(PredictOutput[i - 1], dtype=torch.float32).unsqueeze(0).to(device)  # Shape: (1, 5)\n",
    "                inputs = torch.cat((inputs, new_prediction), dim=0)  # 拼接 -> Shape: (N+1, 5)\n",
    "\n",
    "            # 切出新的参考数据 12 笔 (往前看 12 笔)\n",
    "            X_test = inputs[-LookBackNum:]  # Shape: (LookBackNum, 5)\n",
    "            X_test = X_test.unsqueeze(0)  # Add batch dimension -> Shape: (1, LookBackNum, 5)\n",
    "            # print(\"X_test shape:\", X_test.shape)  # 应为 (1, LookBackNum, 5)\n",
    "\n",
    "            # 前向传播\n",
    "            predicted = model(X_test)  # Shape: (1, 5)\n",
    "            PredictOutput.append(predicted.cpu().numpy().flatten())  # 添加预测值\n",
    "\n",
    "            # 使用回归模型预测发电量\n",
    "            predicted_power = RegressionModel.predict(predicted.cpu().numpy())\n",
    "            PredictPower.append(np.round(predicted_power, 2).flatten())\n",
    "\n",
    "\n",
    "    count += 48  # 每次預測都要預測 48 個，因此加 48 個會切到下一天\n",
    "\n",
    "print(\"Prediction Completed\")\n",
    "\n",
    "# %%\n",
    "#寫預測結果寫成新的CSV檔案\n",
    "# 將陣列轉換為 DataFrame\n",
    "df = pd.DataFrame(PredictPower, columns=['答案'])\n",
    "\n",
    "# 將 DataFrame 寫入 CSV 檔案\n",
    "df_q = pd.read_csv('upload(no answer).csv')\n",
    "output_df = pd.concat([df_q['序號'], df], axis=1)\n",
    "output_df.to_csv('output1.csv', index=False)\n",
    "print('Output CSV File Saved')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "#寫預測結果寫成新的CSV檔案\n",
    "# 將陣列轉換為 DataFrame\n",
    "df = pd.DataFrame(PredictPower, columns=['答案'])\n",
    "\n",
    "# 將 DataFrame 寫入 CSV 檔案\n",
    "df_q = pd.read_csv('upload(no answer).csv')\n",
    "output_df = pd.concat([df_q['序號'], df], axis=1)\n",
    "output_df.to_csv('output1.csv', index=False)\n",
    "print('Output CSV File Saved')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
